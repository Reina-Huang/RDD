---
title: "RDD"
author: "Yu-Ting Huang"
date: "2/15/2021"
output:
  pdf_document: default
  html_document: default
---

#### Github repo and summary (worth 2 points)

    1. Download Hansen_dwi.dta from github at the following address.
 

use https://github.com/scunning1975/causal-inference-class/raw/master/hansen_dwi, clear

 
Create a new github repo named “RDD”.  Inside the RDD directory, put all the subdirectories we’ve discussed in class. Post the link to the repo so I can see it’s done as discussed in your assignment. Save the Hansen_dwi.dta file into your new /data subdirectory.  Note: The outcome variable is “recidivism” or “recid” which is measuring whether the person showed back up in the data within 4 months.

  https://github.com/Reina-Huang/RDD.git
  
    2. In the writing subdirectory, place your assignment. For the first part of this assignment, read Hansen’s paper in the /articles directory of the main class github entitled “Hansen AER”.  Briefly summarize this paper.  What is his research question? What data does he use?  What is his research design, or “identification strategy”?  What are his conclusions?
    
The main question for this paper is that the authors would like to realize whether punishments and sanctions are effective in decreasing drunk driving. They claim this finding is important for improving social welfare, and could assist to formulate the related policy. In order to further construct the model, he utilize administrative records on 512,964 DUI BAC tests in the state of Washington from 1999 to 2007. The reason is that BAC thresholds are the same after 1999 which is 0.08 and 0.15 (aggravated).

Owing to the quantifiable characteristics of BAC, authors could apply local  linear regression discontinuity design to do the estimates.  In addition, the evidences also show that demographic indicators such as age, white/nonwhite and male/female keep constant in the DUI punishment thresholds.  The identification strategy is that allowing the slopes change at the certain DUI (0.08) and severe DUI (0.15)  threshold. To meet the expectation, they assumes recidivism may decrease at specific points if punishment and sanctions have effect.

Finally, they point out recidivism will declining two percentages points which is statistically significant as BAC above the 0.08 threshold during a four year follow-up. Furthermore, conclusion also present people have lower possibilities to repeatedly drunk drive though people do not have previous tests. In other words, consequence means punishment and sanctions have advantages of reducing repeat drunk drivers for both 0.08 DUI threshold and 0.15 aggravated DUI in the short and long run. 

#### Reproducing somewhat Hansen’s results (but just follow directions) (worth 6 points).[2]

    3. In the United States, an officer can arrest a driver if after giving them a blood alcohol content (BAC) test they learn the driver had a BAC of 0.08 or higher. We will only focus on the 0.08 BAC cutoff. We will be ignoring the 0.15 cutoff for all this analysis. Create a dummy equaling 1 if bac1>= 0.08 and 0 otherwise in your do file or R file.

3-

![Caption for the picture.](/Users/mac/OneDrive - The University of Texas at Austin/學習小札/2020 UTAustin/2021 Sp_Causal Inference/RDD Replication/Graph_bac1.png)


    4.The first thing to do in any RDD is look at the raw data and see if there’s any evidence for manipulation (“sorting on the running variable”). If people were capable of manipulating their blood alcohol content (bac1), describe the test we would use to check for this.  Now evaluate whether you see this in these data?  Either recreate Figure 1 using the bac1 variable as your measure of blood alcohol content or use your own density test from software.  Do you find evidence for sorting on the running variable? Explain your results.  Compare what you found to what Hansen found.

4-

    5. The second thing we need to do is check for covariate balance. Recreate Table 2 Panel A but only white male, age and accident (acc) as dependent variables.  Use your equation 1) for this. Are the covariates balanced at the cutoff?  It’s okay if they are not exactly the same as Hansen’s.
    
5-  
    
    6. Recreate Figure 2 panel A-D. You can use the -cmogram- command in Stata to do this. Fit both linear and quadratic with confidence intervals. Discuss what you find and compare it with Hansen’s paper.

6-

    7. Estimate equation (1) with recidivism (recid) as the outcome. This corresponds to Table 3 column 1, but since I am missing some of his variables, your sample size will be the entire dataset of 214,558. Nevertheless, replicate Table 3, column 1, Panels A and B.  Note that these are local linear regressions and Panel A uses as its bandwidth 0.03 to 0.13.  But Panel B has a narrower bandwidth of 0.055 to 0.105.  Your table should have three columns and two A and B panels associated with the different bandwidths.:
    Column 1: control for the bac1 linearly
    Column 2: interact bac1 with cutoff linearly
    Column 3: interact bac1 with cutoff linearly and as a quadratic
    For all analysis, estimate uncertainty using heteroskedastic robust standard errors. [ed: But if you want to show off, use Kolesár and Rothe’s 2018 “honest” confidence intervals (only available in R).]

7-

    8. Recreate the top panel of Figure 3 according to the following rule:
    Fit linear fit using only observations with less than 0.15 bac on the bac1
    Fit quadratic fit using only observations with less than 0.15 bac on the bac1

8-

    9. Discuss what you learned from this exercise. What was the hypothesis you tested and what did you find?  How confident are you in Hansen’s original conclusion? Why/why not?
 
9- 

[1] Again, my preference is that you attempt to create automated tables and automated figures as much as you can.  I’ve placed a simple estout program called ols.do in the estout subdirectory.  You just need to edit.

[2] Much of this advice applies to Stata commands, but you can check the R files for lmb.r to see ways of doing the same in R.
